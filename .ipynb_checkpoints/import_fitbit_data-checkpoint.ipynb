{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#fitbit packages \n",
    "import fitbit\n",
    "from python_fitbit import gather_keys_oauth2 as Oauth2\n",
    "\n",
    "#time libraries\n",
    "from datetime import datetime, timedelta\n",
    "import pause\n",
    "\n",
    "#data importing libraries\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set globals\n",
    "#date I joined Fitbit\n",
    "date_joined_fitbit = '2016-05-21'\n",
    "today = datetime.now().date()\n",
    "days = pd.date_range(start = date_joined_fitbit, end = today, freq = 'D')\n",
    "\n",
    "#import lifting data \n",
    "saved_workouts = glob.glob('fitnotes/Fitnotes*.csv')\n",
    "fitnotes = pd.read_csv(saved_workouts[-1], index_col = 'Date')\n",
    "#get unique workout dates as datetime index as of the first date I joined fitbit\n",
    "lifting_days = pd.to_datetime(fitnotes.index).intersection(days).unique()\n",
    "#for these dates, I did workouts without fitbit activity data; the earliest record\n",
    "#I have is 2016-05-29\n",
    "activities_skip_dates = pd.to_datetime(pd.Index(['2016-05-23', '2016-05-24', '2016-05-25', '2016-05-26']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_until_api_refresh():\n",
    "    '''Sleep until the next time fitbit api refreshes'''\n",
    "    #Identify next top of the hour from now\n",
    "    #add 5 minutes in case fitbit is slow to update\n",
    "    t = datetime.now()\n",
    "    resume_time = t - timedelta(hours = -1, minutes = t.minute - 5, \n",
    "                                seconds = t.second, microseconds = t.microsecond)\n",
    "    print(f'Sleeping until {str(resume_time.time())}')\n",
    "    #pause until identified time\n",
    "    pause.until(resume_time)\n",
    "    \n",
    "def activate_fitbit():\n",
    "    '''\n",
    "    Authorize the script to access my Fitbit data\n",
    "    and return fitbit python object\n",
    "    '''\n",
    "    #import fitbit application credentials as a dictionary\n",
    "    filepath = 'fitbit/fitbit_credentials.txt'\n",
    "    with open(filepath, mode = 'r') as file:\n",
    "        credentials = ast.literal_eval(file.read())\n",
    "    \n",
    "    #instantiate fitbit object\n",
    "    client = fitbit.Fitbit(credentials['client_id'], \n",
    "                           credentials['client_secret'], \n",
    "                           oauth2=True, \n",
    "                           refresh_cb = True,\n",
    "                           access_token=credentials['access_token'], \n",
    "                           refresh_token=credentials['refresh_token'])\n",
    "    return client\n",
    "\n",
    "def get_weight():\n",
    "    '''\n",
    "    Get historical weight data from Fitbit.\n",
    "    Note: I log my weight using the MyFitnessPal app, which Fitbit\n",
    "    downloads from. Because MyFitnessPal does not have a public API, I would\n",
    "    have to download my weight statistics manually. This script allows me to\n",
    "    programmatically access that data through Fitbit's connection to MyFitnessPal\n",
    "    I also use this instead of the time series fitbit method because time series\n",
    "    method imputes days where no weight was entered as the last known date. This way,\n",
    "    I can manually interpolate the interim days' weight myself.\n",
    "    '''\n",
    "    exists = os.path.isfile('fitbit/weight.csv')\n",
    "    try:\n",
    "        #update with latest weight if weight file exists\n",
    "        if exists:\n",
    "            weight = pd.read_csv('fitbit/weight.csv', parse_dates = ['date'])\n",
    "            latest_weight_month = pd.Index(weight.date).snap('MS').max().date()\n",
    "            months = pd.date_range(latest_weight_month, today, freq = 'MS') + pd.DateOffset(months=1)\n",
    "            for month in months:\n",
    "                df = pd.DataFrame(client.get_bodyweight(base_date = month, period = '1m')['weight'])\n",
    "                #append to dataframe\n",
    "                weight = weight.append(df, ignore_index = True, sort = False)\n",
    "            #dropping duplicates in case I'm re-adding older data\n",
    "            weight = weight.drop_duplicates(subset = 'date')\n",
    "\n",
    "        #if there is no weight file, backfill weight data from scratch; offset by a month since data\n",
    "        #collection looks backward a month; this lets me get current data from this month as well\n",
    "        else:\n",
    "            months = pd.date_range(start = date_joined_fitbit, end = today, freq = 'MS') + pd.DateOffset(months=1)\n",
    "            #create empty list\n",
    "            weight = []\n",
    "            #iterate through period index of frequency month\n",
    "            for month in months:\n",
    "                #create dataframe of weight data starting from the first of the month\n",
    "                #to the end of the month\n",
    "                df = pd.DataFrame(client.get_bodyweight(base_date = month, period = '1m')['weight'])\n",
    "                #append to list\n",
    "                weight.append(df)\n",
    "            #concatenate into dataframe and export\n",
    "            weight = pd.concat(weight, ignore_index = True, sort = False)\n",
    "    except:\n",
    "        sleep_until_api_refresh()\n",
    "        \n",
    "    weight.to_csv('fitbit/weight.csv', index = False)\n",
    "    print('Weight update complete')\n",
    "\n",
    "def get_intraday_data(data):\n",
    "    '''\n",
    "    Get heart rata data at sub-minute granularity on workout days,\n",
    "    updating for days I'm missing. \n",
    "    \"heart\" for heart rate, \"calories\" for calories\n",
    "    '''\n",
    "    \n",
    "    '''identify days for which no heart rate data is downloaded'''\n",
    "    #if a download folder doesn't exist, create it\n",
    "    if os.path.exists(f\"fitbit/{data}/\") == False:\n",
    "        os.makedirs(f\"fitbit/{data}/\")\n",
    "        \n",
    "    #get list of heart rate files\n",
    "    current_files = glob.glob(f'fitbit/{data}/*.json')\n",
    "    \n",
    "    #if there are no files in the folder, set the dates to download as \n",
    "    #the lifting days\n",
    "    if len(current_files) == 0:\n",
    "        dates_to_download = lifting_days\n",
    "    \n",
    "    #if there are some files downloaded, identify days for which there is no data\n",
    "    else:\n",
    "        #create index of filelist and replace all non-digit characters, leaving only the date\n",
    "        downloaded_days = pd.Index(current_files).str.replace('\\D+', '')\n",
    "        #convert to datetime index \n",
    "        downloaded_days = pd.to_datetime(downloaded_days)\n",
    "\n",
    "        #get dates in lifting days but not saved in a folder\n",
    "        dates_to_download = lifting_days.difference(downloaded_days)\n",
    "\n",
    "    '''download intraday data for all undownloaded days'''\n",
    "    #set dictionary of level of granularity to pull for each data type\n",
    "    if data == 'heart':\n",
    "        interval = '1sec'\n",
    "    else:\n",
    "        interval = '1min'\n",
    "    \n",
    "    if len(dates_to_download) == 0:\n",
    "        print(f'{data} already up to date')\n",
    "    else:   \n",
    "        #download intraday data for all undownloaded days\n",
    "        for day in dates_to_download:\n",
    "            try:\n",
    "                #convert date from timestamp to string\n",
    "                day = str(day.date())\n",
    "                #get intraday heart rate data at second granularity\n",
    "                series = client.intraday_time_series(f'activities/{data}', \n",
    "                                                        base_date= day, \n",
    "                                                        detail_level= interval)\n",
    "                #save to json\n",
    "                with open(f'fitbit/{data}/{data}_{day}.json', 'w') as outfile:\n",
    "                    json.dump(series, outfile)\n",
    "\n",
    "            except:\n",
    "                #if the function hits an exception by hitting the fitbit rate limit, \n",
    "                #sleep for an hour\n",
    "                #Fitbit's api has a rate limit of 150 requests per hour\n",
    "                #which resets at the top of each hour, not necessarily an hour\n",
    "                #after reaching the limit\n",
    "                print(Exception)\n",
    "                sleep_until_api_refresh()\n",
    "        print(f'{data} update complete')\n",
    "\n",
    "def get_activities_report():\n",
    "    '''Get list of activities logged in fitbit tracker'''\n",
    "    #make finite loop\n",
    "    files = glob.glob('fitbit/activities/*.csv')\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        dates_to_download = lifting_days\n",
    "\n",
    "    else:\n",
    "        #import downloaded activities\n",
    "        activities = pd.concat([pd.read_csv(file, parse_dates = ['startTime'], usecols = ['startTime']) for file in files])\n",
    "        activities = (activities\n",
    "                      .assign(startTime = pd.to_datetime(activities.startTime.dt.date))\n",
    "                      .drop_duplicates(subset = 'startTime')\n",
    "                      .set_index('startTime')\n",
    "                      .asfreq('D')\n",
    "                     )\n",
    "        #convert to datetime index \n",
    "        downloaded_days = activities.index.append(activities_skip_dates)\n",
    "        #get dates in lifting days but not saved in a folder\n",
    "        dates_to_download = lifting_days.difference(downloaded_days)\n",
    "        if len(dates_to_download) == 0:\n",
    "            print('Activities already up to date')\n",
    "            return\n",
    "\n",
    "    afterDate = dates_to_download[0].date()\n",
    "    for i in range(len(dates_to_download)):\n",
    "        try:\n",
    "            if afterDate > dates_to_download[i + 1]:\n",
    "                continue\n",
    "        except IndexError:\n",
    "            print('End of date range reached: Proceeding to last date range.')\n",
    "        afterDate = dates_to_download[i].date()\n",
    "        try:\n",
    "            #ping url for the next 20 activities >= afterDate\n",
    "            parameters = f'afterDate={afterDate}&offset=0&limit=20&sort=asc'\n",
    "            activities = client.make_request(f'https://api.fitbit.com/1/user/-/activities/list.json&{parameters}')\n",
    "            #set the afterdate as the latest startTime date; there will be\n",
    "            #overlap, but keeping overlap is only way to ensure some\n",
    "            #activities are fully captured since the 20 activity limit\n",
    "            #can hit before reaching all activities done on a particular\n",
    "            #date. Note that getting the date value sometimes rounds \n",
    "            #the date up, so there's some error in the nomenclature\n",
    "            #but the data is unaffected since afterDate is pulled from\n",
    "            #columns without modifying them\n",
    "            df = pd.DataFrame(activities['activities'])\n",
    "            afterDate = df.startTime.apply(pd.to_datetime).dt.date.max()\n",
    "            #download file as of 20 activities at or after afterDate\n",
    "            df.to_csv(f'fitbit/activities/activities_{afterDate}.csv', index = False)\n",
    "        except:\n",
    "            sleep_until_api_refresh()\n",
    "    print('Activity log update complete')\n",
    "    return\n",
    "\n",
    "def get_sleep():\n",
    "    '''\n",
    "    Get all fitbit sleep records.\n",
    "    This function gets all sleep records instead of filtering down by workout day\n",
    "    because fitbit allows larger spans of dates per function call, saving api calls\n",
    "    for much more data\n",
    "    '''\n",
    "    #get list of heart rate files\n",
    "    files = glob.glob(f'fitbit/sleep/*.json')\n",
    "    \n",
    "    #if there are no files in the folder, set the dates to download as \n",
    "    #the lifting days\n",
    "    if len(files) == 0:\n",
    "        date_span = pd.date_range(date_joined_fitbit, today, freq = '1M').date\n",
    "    \n",
    "    else:\n",
    "        #create index of filelist and replace all non-digit characters, leaving only the dates\n",
    "        #apply lambda function grabbing last 8 characters, representing the end date\n",
    "        downloaded_days = pd.Index(files).str.replace('\\D+', '').map(lambda x: x[-8:])\n",
    "        #convert to datetime index \n",
    "        downloaded_days = pd.to_datetime(downloaded_days)\n",
    "        latest_date = downloaded_days.max()\n",
    "        #set this to update every other day just to make it work\n",
    "        date_span = pd.date_range(latest_date, today, freq = '1D').date\n",
    "    try:\n",
    "        for counter in range(len(date_span)):\n",
    "            if counter + 1 < len(date_span):\n",
    "                start_date = date_span[counter] \n",
    "                end_date = (date_span[counter + 1] - pd.DateOffset(days = 1)).date()\n",
    "                url = f'https://api.fitbit.com/1.2/user/-/sleep/date/{start_date}/{end_date}.json'\n",
    "                sleep = client.make_request(url)\n",
    "                #name files as of a (month - 1 day) days <= end date\n",
    "                with open(f'fitbit/sleep/sleep_{start_date}_{end_date}.json', 'w') as file:\n",
    "                    json.dump(sleep, file)\n",
    "            else:\n",
    "                print('End of date range reached: Finishing sleep update')\n",
    "    except:\n",
    "        sleep_until_api_refresh()\n",
    "        \n",
    "    print('Sleep update complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart already up to date\n",
      "calories already up to date\n",
      "steps already up to date\n",
      "distance already up to date\n",
      "floors already up to date\n",
      "elevation already up to date\n",
      "Activities already up to date\n",
      "End of date range reached: Finishing sleep update\n",
      "Sleep update complete\n",
      "Weight update complete\n"
     ]
    }
   ],
   "source": [
    "client = activate_fitbit()\n",
    "activity_indicators = ['heart', 'calories', 'steps', 'distance',\n",
    "                       'floors', 'elevation']\n",
    "for indicator in activity_indicators:\n",
    "    get_intraday_data(indicator)\n",
    "get_activities_report()\n",
    "get_sleep()\n",
    "get_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Handle updates on days that have already been pulled but not all data was collected\n",
    "    - Somehow determine whether data is complete or not. Maybe reaching into the time aspect of the data could work. Until then, refreshing once a day seems the better choice, if inflexible\n",
    "    - Maybe capture up until the previous day so I don't get incomplete data from the current day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
