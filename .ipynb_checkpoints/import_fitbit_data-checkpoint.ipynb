{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#fitbit packages \n",
    "import fitbit\n",
    "from python_fitbit import gather_keys_oauth2 as Oauth2\n",
    "\n",
    "#time libraries\n",
    "from datetime import datetime, timedelta\n",
    "import pause\n",
    "\n",
    "#data importing libraries\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set globals\n",
    "#date I joined Fitbit\n",
    "date_joined_fitbit = '2016-05-21'\n",
    "today = datetime.now().date()\n",
    "days = pd.date_range(start = date_joined_fitbit, end = today, freq = 'D')\n",
    "\n",
    "#import lifting data \n",
    "lifts = pd.read_csv('fitnotes/Fitnotes_Export.csv', index_col = 'Date')\n",
    "#get unique workout dates as datetime index as of the first date I joined fitbit\n",
    "lifting_days = pd.to_datetime(lifts.index).intersection(days).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_until_api_refresh():\n",
    "    '''Sleep until the next time fitbit api refreshes'''\n",
    "    #Identify next top of the hour from now\n",
    "    #add 5 minutes in case fitbit is slow to update\n",
    "    t = datetime.now()\n",
    "    resume_time = t - timedelta(hours = -1, minutes = t.minute - 5, \n",
    "                                seconds = t.second, microseconds = t.microsecond)\n",
    "    print(f'Sleeping until {str(resume_time.time())}')\n",
    "    #pause until identified time\n",
    "    pause.until(resume_time)\n",
    "    \n",
    "def activate_fitbit():\n",
    "    '''\n",
    "    Authorize the script to access my Fitbit data\n",
    "    and return fitbit python object\n",
    "    '''\n",
    "    #import fitbit application credentials as a dictionary\n",
    "    filepath = 'fitbit/fitbit_credentials.txt'\n",
    "    with open(filepath, mode = 'r') as file:\n",
    "        credentials = ast.literal_eval(file.read())\n",
    "    \n",
    "    #instantiate fitbit object\n",
    "    client = fitbit.Fitbit(credentials['client_id'], \n",
    "                           credentials['client_secret'], \n",
    "                           oauth2=True, \n",
    "                           refresh_cb = True,\n",
    "                           access_token=credentials['access_token'], \n",
    "                           refresh_token=credentials['refresh_token'])\n",
    "    return client\n",
    "\n",
    "def get_sleep(days):\n",
    "    sleep_list = []\n",
    "    for day in days:\n",
    "        json = client.get_sleep(day)\n",
    "        stats = pd.DataFrame(json['sleep'])\n",
    "        summary = pd.DataFrame(json['summary'], index = [0])\n",
    "        df = pd.concat([stats, summary], axis = 1)\n",
    "        sleep_list.append(df)\n",
    "    sleep = pd.concat(sleep_list, ignore_index = True, sort = False)\n",
    "    sleep.to_csv('sleep.csv', index = False)\n",
    "    return sleep\n",
    "\n",
    "def get_weight():\n",
    "    '''\n",
    "    Get historical weight data from Fitbit.\n",
    "    Note: I log my weight using the MyFitnessPal app, which Fitbit\n",
    "    downloads from. Because MyFitnessPal does not have a public API, I would\n",
    "    have to download my weight statistics manually. This script allows me to\n",
    "    programmatically access that data through Fitbit's connection to MyFitnessPal\n",
    "    I also use this instead of the time series fitbit method because time series\n",
    "    method imputes days where no weight was entered as the last known date. This way,\n",
    "    I can manually interpolate the interim days' weight myself.\n",
    "    '''\n",
    "    exists = os.path.isfile('fitbit/weight.csv')\n",
    "    \n",
    "    #update with latest weight if weight file exists\n",
    "    if exists:\n",
    "        weight = pd.read_csv('fitbit/weight.csv', parse_dates = ['date'])\n",
    "        latest_weight_month = pd.Index(weight.date).snap('MS').max().date()\n",
    "        months = pd.date_range(latest_weight_month, today, freq = 'MS') + pd.DateOffset(months=1)\n",
    "        for month in months:\n",
    "            df = pd.DataFrame(client.get_bodyweight(base_date = month, period = '1m')['weight'])\n",
    "            #append to dataframe\n",
    "            weight = weight.append(df, ignore_index = True, sort = False)\n",
    "        #dropping duplicates in case I'm re-adding older data\n",
    "        weight = weight.drop_duplicates(subset = 'date')\n",
    "    \n",
    "    #if there is no weight file, backfill weight data from scratch; offset by a month since data\n",
    "    #collection looks backward a month; this lets me get current data from this month as well\n",
    "    else:\n",
    "        months = pd.date_range(start = date_joined_fitbit, end = today, freq = 'MS') + pd.DateOffset(months=1)\n",
    "        #create empty list\n",
    "        weight = []\n",
    "        #iterate through period index of frequency month\n",
    "        for month in months:\n",
    "            #create dataframe of weight data starting from the first of the month\n",
    "            #to the end of the month\n",
    "            df = pd.DataFrame(client.get_bodyweight(base_date = month, period = '1m')['weight'])\n",
    "            #append to list\n",
    "            weight.append(df)\n",
    "        #concatenate into dataframe and export\n",
    "        weight = pd.concat(weight, ignore_index = True, sort = False)\n",
    "        \n",
    "    weight.to_csv('fitbit/weight.csv', index = False)\n",
    "\n",
    "def get_intraday_data(data):\n",
    "    '''\n",
    "    Get heart rata data at sub-minute granularity on workout days,\n",
    "    updating for days I'm missing. \n",
    "    \"heart\" for heart rate, \"calories\" for calories\n",
    "    '''\n",
    "    \n",
    "    '''identify days for which no heart rate data is downloaded'''\n",
    "    #if a download folder doesn't exist, create it\n",
    "    if os.path.exists(f\"fitbit/{data}/\") == False:\n",
    "        os.makedirs(f\"fitbit/{data}/\")\n",
    "        \n",
    "    #get list of heart rate files\n",
    "    current_files = glob.glob(f'fitbit/{data}/*.json')\n",
    "    \n",
    "    #if there are no files in the folder, set the dates to download as \n",
    "    #the lifting days\n",
    "    if len(current_files) == 0:\n",
    "        dates_to_download = lifting_days\n",
    "    \n",
    "    #if there are some files downloaded, identify days for which there is no data\n",
    "    else:\n",
    "        #create index of filelist and replace all non-digit characters, leaving only the date\n",
    "        downloaded_days = pd.Index(current_files).str.replace('\\D+', '')\n",
    "        #convert to datetime index \n",
    "        downloaded_days = pd.to_datetime(downloaded_days)\n",
    "\n",
    "        #get dates in lifting days but not saved in a folder\n",
    "        dates_to_download = lifting_days.difference(downloaded_days)\n",
    "\n",
    "    '''download intraday data for all undownloaded days'''\n",
    "    #set dictionary of level of granularity to pull for each data type\n",
    "    if data == 'heart':\n",
    "        interval = '1sec'\n",
    "    else:\n",
    "        interval = '1min'\n",
    "    \n",
    "    if len(dates_to_download) == 0:\n",
    "        print(f'{data} already up to date')\n",
    "    else:   \n",
    "        #download intraday data for all undownloaded days\n",
    "        for day in dates_to_download:\n",
    "            try:\n",
    "                #convert date from timestamp to string\n",
    "                day = str(day.date())\n",
    "                #get intraday heart rate data at second granularity\n",
    "                series = client.intraday_time_series(f'activities/{data}', \n",
    "                                                        base_date= day, \n",
    "                                                        detail_level= interval)\n",
    "                #save to json\n",
    "                with open(f'fitbit/{data}/{data}_{day}.json', 'w') as outfile:\n",
    "                    json.dump(series, outfile)\n",
    "\n",
    "            except:\n",
    "                #if the function hits an exception by hitting the fitbit rate limit, \n",
    "                #sleep for an hour\n",
    "                #Fitbit's api has a rate limit of 150 requests per hour\n",
    "                #which resets at the top of each hour, not necessarily an hour\n",
    "                #after reaching the limit\n",
    "                print(str(Exception))\n",
    "                sleep_until_api_refresh()\n",
    "        print(f'{data} update complete')\n",
    "\n",
    "def get_activities_report():\n",
    "    '''Get list of activities logged in fitbit tracker'''\n",
    "    \n",
    "    files = glob.glob('fitbit/activities/*.csv')\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        afterDate = pd.to_datetime(date_joined_fitbit).date()\n",
    "\n",
    "    else:\n",
    "        #create index of filelist and replace all non-digit characters, leaving only the date\n",
    "        downloaded_days = pd.Index(files).str.replace('\\D+', '')\n",
    "        #convert to datetime index \n",
    "        downloaded_days = pd.to_datetime(downloaded_days)\n",
    "        #get dates in lifting days but not saved in a folder\n",
    "        dates_to_download = lifting_days.difference(downloaded_days)\n",
    "        afterDate = dates_to_download.min().date()\n",
    "\n",
    "    while afterDate < lifting_days.max().date():\n",
    "        try:\n",
    "            parameters = f'afterDate={afterDate}&offset=0&limit=20&sort=asc'\n",
    "            activities = client.make_request(f'https://api.fitbit.com/1/user/-/activities/list.json&{parameters}')\n",
    "            df = pd.DataFrame(activities['activities'])\n",
    "            df['originalStartTime'] = pd.to_datetime(df.originalStartTime).dt.date\n",
    "            afterDate = df.originalStartTime.max()\n",
    "            earliest_date = str(df.originalStartTime.min())\n",
    "            df.to_csv(f'fitbit/activities/activities_{earliest_date}.csv', index = False)\n",
    "        except:\n",
    "            sleep_until_api_refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart update complete\n",
      "calories update complete\n",
      "steps update complete\n",
      "distance update complete\n",
      "floors update complete\n",
      "elevation update complete\n"
     ]
    }
   ],
   "source": [
    "client = activate_fitbit()\n",
    "\n",
    "activity_indicators = ['heart', 'calories', 'steps', 'distance',\n",
    "                       'floors', 'elevation']\n",
    "for indicator in activity_indicators:\n",
    "    get_intraday_data(indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_activities_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Handle updates on days that have already been pulled but not all data was collected\n",
    "    - Somehow determine whether data is complete or not. Maybe reaching into the time aspect of the data could work. Until then, refreshing once a day seems the better choice, if inflexible\n",
    "    - Maybe capture up until the previous day so I don't get incomplete data from the current day\n",
    "- Handle exception when improper grant is given because tokens have elapsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
